{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5ca83cf-73bd-4e2f-ae55-ee8293344b68",
   "metadata": {},
   "source": [
    "# Loading and Cleaning/Preparing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "791912ca-b21c-4257-92e6-16efd39bcb50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in dataset: ['Country Code', 'City', 'Location', 'Coordinates', 'Pollutant', 'Source Name', 'Unit', 'Value', 'Last Updated', 'Country Label']\n",
      "  Country Code City Location                             Coordinates  \\\n",
      "0           CN  NaN    市八十六中             23.1047, 113.43319999999999   \n",
      "1           CN  NaN     市农科院                       21.9508, 108.6553   \n",
      "2           CN  NaN     市发改委                       29.8454, 114.3107   \n",
      "3           CN  NaN       市委  30.457600000000003, 106.63030000000002   \n",
      "4           CN  NaN     市委党校            27.731400000000004, 112.0194   \n",
      "\n",
      "  Pollutant   Source Name   Unit  Value               Last Updated  \\\n",
      "0        O3  ChinaAQIData  µg/m³   36.0  2021-08-09T12:00:00+01:00   \n",
      "1       SO2  ChinaAQIData  µg/m³    7.0  2020-12-31T16:00:00+00:00   \n",
      "2     PM2.5  ChinaAQIData  µg/m³   26.0  2021-08-09T12:00:00+01:00   \n",
      "3        O3  ChinaAQIData  µg/m³   91.0  2021-08-09T12:00:00+01:00   \n",
      "4       NO2  ChinaAQIData  µg/m³   19.0  2021-08-09T12:00:00+01:00   \n",
      "\n",
      "  Country Label  \n",
      "0         China  \n",
      "1         China  \n",
      "2         China  \n",
      "3         China  \n",
      "4         China  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "csv_file = \"openaq.csv\"\n",
    "\n",
    "openaq_df = pd.read_csv(csv_file, sep=';', low_memory=False)\n",
    "\n",
    "print(\"Columns in dataset:\", openaq_df.columns.tolist())\n",
    "print(openaq_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "587b377a-51db-4210-912c-0af958b242d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique countries in dataset:\n",
      "['China' 'Colombia' 'Cyprus' 'Czech Republic' 'Germany' 'Denmark'\n",
      " 'Ecuador' 'Estonia' 'Spain' 'Finland' 'France' 'United Kingdom' 'Greece'\n",
      " 'Hong Kong, China' 'Korea, Republic of' 'Lithuania' 'Luxembourg' 'Latvia'\n",
      " 'Montenegro' 'Macedonia, The former Yugoslav Rep. of' 'Mongolia' 'Malta'\n",
      " 'Mexico' 'Japan' 'Netherlands' 'Norway' 'Nepal' 'Peru' 'Poland' 'India'\n",
      " 'Iraq' 'Iceland' 'Italy' 'Croatia' 'Hungary' 'Israel' 'Kyrgyzstan'\n",
      " 'Taiwan, China' 'United States' 'Thailand' 'Turkey' 'Serbia'\n",
      " 'Russian Federation' 'Sweden' 'Singapore' 'Slovenia' 'Slovakia'\n",
      " 'South Africa' nan 'West Bank and Gaza Strip' 'Portugal' 'Romania'\n",
      " 'Austria' 'Australia' 'Canada' 'Switzerland' 'Chile'\n",
      " 'Bosnia and Herzegovina' 'Belgium' 'Andorra' 'United Arab Emirates'\n",
      " 'Argentina' 'Bulgaria' 'Brazil' 'Ghana' 'Indonesia' 'Ireland' 'Kenya'\n",
      " 'Trinidad and Tobago' 'New Zealand' 'Chad' 'Puerto Rico' 'Qatar' 'Egypt'\n",
      " 'Serbia and Montenegro' 'Gibraltar' 'Jordan' 'Saudi Arabia' 'Uzbekistan'\n",
      " \"Lao People's Dem. Rep.\" 'Malaysia' 'Nigeria' 'Tajikistan' 'Oman'\n",
      " 'Pakistan' 'Congo, Democratic Republic of the' 'Mozambique' 'San Marino'\n",
      " 'Senegal' 'Bahrain' 'Guatemala' 'Sri Lanka' 'Belize' 'Nicaragua' 'Rwanda'\n",
      " 'Ethiopia' 'Mali' 'Bangladesh' 'Myanmar' 'Moldova, Republic of'\n",
      " 'Central African Republic' 'Sudan, The Republic of' 'Bermuda'\n",
      " \"Côte d'Ivoire\" 'Armenia' 'Guinea' 'Kuwait' 'Burkina Faso' 'USSR'\n",
      " 'Viet Nam' 'Azerbaijan' 'Afghanistan' 'Turkmenistan' 'Gabon' 'Madagascar'\n",
      " 'Costa Rica' 'Kazakhstan' 'Morocco' 'Algeria' 'Uganda'\n",
      " 'Antigua and Barbuda' 'Philippines' 'Paraguay']\n"
     ]
    }
   ],
   "source": [
    "print(\"Unique countries in dataset:\")\n",
    "print(openaq_df['Country Label'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ed01a892-0a0e-44f3-8a2e-2c9655577860",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique cities: 4464\n",
      "Number of NaN city values: 29146\n",
      "\n",
      "Unique cities in dataset:\n",
      "[nan 'Medellin' 'Αγία Μαρίνα Ξυλιάτου - Σταθμός Υποβάθρου' ... 'Svalöv'\n",
      " 'LJ Bežigrad' 'Złockie']\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of unique cities:\", openaq_df['City'].nunique())\n",
    "\n",
    "print(\"Number of NaN city values:\", openaq_df['City'].isna().sum())\n",
    "\n",
    "print(\"\\nUnique cities in dataset:\")\n",
    "print(openaq_df['City'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a9e1de09-d87e-490a-8db1-bd8c57e1179d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique pollutants in dataset:\n",
      "['O3' 'SO2' 'PM2.5' 'NO2' 'CO' 'PM10' 'NO' 'PM1' 'RELATIVEHUMIDITY'\n",
      " 'TEMPERATURE' 'NOX' 'UM003' 'BC']\n"
     ]
    }
   ],
   "source": [
    "print(\"Unique pollutants in dataset:\")\n",
    "print(openaq_df['Pollutant'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3741ea07-c3b5-4526-886f-bbc2d157c154",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Earliest date: 2014-03-13 12:00:00+00:00\n",
      "Latest date: 2025-01-31 23:00:00+00:00\n",
      "Years available in dataset:\n",
      "[2021 2020 2024 2022 2025 2019 2023 2018 2016 2017 2014 2015]\n"
     ]
    }
   ],
   "source": [
    "# First convert to datetime if not done already\n",
    "openaq_df['Last Updated'] = pd.to_datetime(openaq_df['Last Updated'], errors='coerce', utc=True)\n",
    "\n",
    "# Check date range\n",
    "print(\"Earliest date:\", openaq_df['Last Updated'].min())\n",
    "print(\"Latest date:\", openaq_df['Last Updated'].max())\n",
    "\n",
    "# List all years available\n",
    "print(\"Years available in dataset:\")\n",
    "print(openaq_df['Last Updated'].dt.year.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a4edd95c-18ed-4bf2-9432-635368a2bd57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dublin: 8 rows\n",
      "London: 45 rows\n",
      "Paris: 48 rows\n",
      "Delhi: 0 rows\n",
      "Beijing: 2 rows\n"
     ]
    }
   ],
   "source": [
    "target_cities = [\"Dublin\", \"London\", \"Paris\", \"Delhi\", \"Beijing\"]\n",
    "\n",
    "for city in target_cities:\n",
    "    matches = openaq_df['City'].str.contains(city, case=False, na=False)\n",
    "    print(f\"{city}: {matches.sum()} rows\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ce9d7b70-f106-4c1e-a7e5-374e824af961",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Country Code City Location                             Coordinates  \\\n",
      "0           CN  NaN    市八十六中             23.1047, 113.43319999999999   \n",
      "1           CN  NaN     市农科院                       21.9508, 108.6553   \n",
      "2           CN  NaN     市发改委                       29.8454, 114.3107   \n",
      "3           CN  NaN       市委  30.457600000000003, 106.63030000000002   \n",
      "4           CN  NaN     市委党校            27.731400000000004, 112.0194   \n",
      "\n",
      "  Pollutant   Source Name   Unit  Value              Last Updated  \\\n",
      "0        O3  ChinaAQIData  µg/m³   36.0 2021-08-09 11:00:00+00:00   \n",
      "1       SO2  ChinaAQIData  µg/m³    7.0 2020-12-31 16:00:00+00:00   \n",
      "2     PM2.5  ChinaAQIData  µg/m³   26.0 2021-08-09 11:00:00+00:00   \n",
      "3        O3  ChinaAQIData  µg/m³   91.0 2021-08-09 11:00:00+00:00   \n",
      "4       NO2  ChinaAQIData  µg/m³   19.0 2021-08-09 11:00:00+00:00   \n",
      "\n",
      "  Country Label  Latitude  Longitude  \n",
      "0         China   23.1047   113.4332  \n",
      "1         China   21.9508   108.6553  \n",
      "2         China   29.8454   114.3107  \n",
      "3         China   30.4576   106.6303  \n",
      "4         China   27.7314   112.0194  \n"
     ]
    }
   ],
   "source": [
    "openaq_df[[\"Latitude\", \"Longitude\"]] = (openaq_df[\"Coordinates\"].str.split(\",\", expand=True).astype(float))\n",
    "\n",
    "print(openaq_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "de5f5066-395a-459e-aff0-51d298b62e96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Country Code     City Location                             Coordinates  \\\n",
      "0           CN  Unknown    市八十六中             23.1047, 113.43319999999999   \n",
      "1           CN  Unknown     市农科院                       21.9508, 108.6553   \n",
      "2           CN  Unknown     市发改委                       29.8454, 114.3107   \n",
      "3           CN  Unknown       市委  30.457600000000003, 106.63030000000002   \n",
      "4           CN  Unknown     市委党校            27.731400000000004, 112.0194   \n",
      "\n",
      "  Pollutant   Source Name   Unit  Value              Last Updated  \\\n",
      "0        O3  ChinaAQIData  µg/m³   36.0 2021-08-09 11:00:00+00:00   \n",
      "1       SO2  ChinaAQIData  µg/m³    7.0 2020-12-31 16:00:00+00:00   \n",
      "2     PM2.5  ChinaAQIData  µg/m³   26.0 2021-08-09 11:00:00+00:00   \n",
      "3        O3  ChinaAQIData  µg/m³   91.0 2021-08-09 11:00:00+00:00   \n",
      "4       NO2  ChinaAQIData  µg/m³   19.0 2021-08-09 11:00:00+00:00   \n",
      "\n",
      "  Country Label  Latitude  Longitude  \n",
      "0         China   23.1047   113.4332  \n",
      "1         China   21.9508   108.6553  \n",
      "2         China   29.8454   114.3107  \n",
      "3         China   30.4576   106.6303  \n",
      "4         China   27.7314   112.0194  \n"
     ]
    }
   ],
   "source": [
    "openaq_df[\"City\"] = openaq_df[\"City\"].fillna(\"Unknown\")\n",
    "\n",
    "print(openaq_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d7a9486-c529-4879-993f-4d7461563689",
   "metadata": {},
   "source": [
    "# Data Aggregation for Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "3e74f64a-af61-482d-90f9-d66393a664ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Country Label Pollutant   avg_value\n",
      "0                 Afghanistan     PM2.5 -431.500000\n",
      "1                     Algeria     PM2.5   14.000000\n",
      "2                     Andorra        CO  500.000000\n",
      "3                     Andorra        NO   16.900000\n",
      "4                     Andorra       NO2   36.500000\n",
      "..                        ...       ...         ...\n",
      "602                  Viet Nam     PM2.5   26.000000\n",
      "603  West Bank and Gaza Strip        CO    0.433333\n",
      "604  West Bank and Gaza Strip       NO2    0.018467\n",
      "605  West Bank and Gaza Strip        O3    0.010167\n",
      "606  West Bank and Gaza Strip       SO2    0.000267\n",
      "\n",
      "[607 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "country_pollution = openaq_df.groupby([\"Country Label\", \"Pollutant\"], as_index = False).agg(avg_value = (\"Value\", \"mean\"))\n",
    "\n",
    "print(country_pollution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "bfca4d11-f9c9-403e-99bf-3972cb8e79d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Date Pollutant   avg_value\n",
      "0     2014-03-13     PM2.5    5.000000\n",
      "1     2014-08-12     PM2.5    7.100000\n",
      "2     2015-08-21     PM2.5   36.900000\n",
      "3     2016-02-09     PM2.5   10.000000\n",
      "4     2016-02-16        CO  740.700000\n",
      "...          ...       ...         ...\n",
      "6038  2025-01-31        O3   31.038400\n",
      "6039  2025-01-31       PM1   10.196597\n",
      "6040  2025-01-31      PM10   15.021268\n",
      "6041  2025-01-31     PM2.5    3.292397\n",
      "6042  2025-01-31       SO2    4.446568\n",
      "\n",
      "[6043 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "openaq_df[\"Date\"] = openaq_df[\"Last Updated\"].dt.date\n",
    "\n",
    "time_pollution = openaq_df.groupby([\"Date\", \"Pollutant\"], as_index = False).agg(avg_value = (\"Value\", \"mean\"))\n",
    "\n",
    "print(time_pollution)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1651639b-f432-41ba-9369-a5cc2520e24f",
   "metadata": {},
   "source": [
    "# Interactive Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2641b1d5-8537-4063-a0fa-3bd8c64b6c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dash\n",
    "from dash import dcc, html\n",
    "from dash.dependencies import Input, Output\n",
    "import plotly.express as px\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "pollutants = [\"All\", \"PM2.5\", \"PM10\", \"NO2\", \"SO2\", \"O3\", \"CO\"]\n",
    "# Keep only the pollutant types we want to show (exclude 'All' since it's an option not a real pollutant)\n",
    "openaq_df = openaq_df[openaq_df[\"Pollutant\"].isin([p for p in pollutants if p != 'All'])].copy()\n",
    "\n",
    "# Load world data for continent mapping (used to split sunburst by continent)\n",
    "try:\n",
    "    world_df = pd.read_csv('world_data.csv')\n",
    "    # Build multiple lookup tables to improve matching\n",
    "    country_to_region = dict(zip(world_df['name'].str.lower().str.strip(), world_df['region'].fillna('Unknown')))\n",
    "    alpha2_to_region = dict(zip(world_df['alpha-2'].astype(str).str.upper(), world_df['region'].fillna('Unknown')))\n",
    "    alpha3_to_region = dict(zip(world_df['alpha-3'].astype(str).str.upper(), world_df['region'].fillna('Unknown')))\n",
    "\n",
    "    # Use pycountry when available for better matching; fall back to fuzzy matching\n",
    "    try:\n",
    "        import pycountry\n",
    "    except Exception:\n",
    "        pycountry = None\n",
    "\n",
    "    import difflib\n",
    "\n",
    "    def resolve_continent(country_label):\n",
    "        \"\"\"Resolve a country label to a region/continent using multiple strategies.\n",
    "        Returns None if no reasonable match is found.\n",
    "        \"\"\"\n",
    "        if not isinstance(country_label, str) or not country_label.strip():\n",
    "            return None\n",
    "        key = country_label.lower().strip()\n",
    "\n",
    "        # Handle known legacy or variant names explicitly\n",
    "        special = {\n",
    "            \"lao people's dem. rep.\": 'Asia',\n",
    "            \"lao people's dem rep\": 'Asia',\n",
    "            \"lao people's democratic republic\": 'Asia',\n",
    "            \"lao people's democratic rep\": 'Asia',\n",
    "            \"lao people's dem. rep\": 'Asia',\n",
    "            \"lao people's republic\": 'Asia',\n",
    "            'lao peoples dem rep': 'Asia',\n",
    "            'lao pdr': 'Asia',\n",
    "            'ussr': 'Europe',\n",
    "            'soviet union': 'Europe',\n",
    "            'serbia and montenegro': 'Europe',\n",
    "            'serbia & montenegro': 'Europe'\n",
    "        }\n",
    "        if key in special:\n",
    "            return special[key]\n",
    "\n",
    "        # Direct exact name match\n",
    "        if key in country_to_region:\n",
    "            return country_to_region[key]\n",
    "\n",
    "        # Try resolving with pycountry to get ISO codes and map with those\n",
    "        if pycountry is not None:\n",
    "            try:\n",
    "                c = pycountry.countries.lookup(country_label)\n",
    "                code2 = getattr(c, 'alpha_2', None)\n",
    "                code3 = getattr(c, 'alpha_3', None)\n",
    "                if code2 and code2.upper() in alpha2_to_region:\n",
    "                    return alpha2_to_region[code2.upper()]\n",
    "                if code3 and code3.upper() in alpha3_to_region:\n",
    "                    return alpha3_to_region[code3.upper()]\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "        # Fuzzy match against known country names\n",
    "        match = difflib.get_close_matches(key, country_to_region.keys(), n=1, cutoff=0.82)\n",
    "        if match:\n",
    "            return country_to_region[match[0]]\n",
    "\n",
    "        # Try simplified name (remove parentheses, parts after comma)\n",
    "        simplified = key.split('(')[0].split(',')[0].strip()\n",
    "        if simplified in country_to_region:\n",
    "            return country_to_region[simplified]\n",
    "\n",
    "        return None\n",
    "\n",
    "except Exception:\n",
    "    country_to_region = {}\n",
    "    def resolve_continent(x):\n",
    "        return None\n",
    "\n",
    "app = dash.Dash(__name__)\n",
    "app.title = \"Global Air Quality Dashboard\"\n",
    "\n",
    "# Layout\n",
    "app.layout = html.Div([\n",
    "    html.Div([html.H1(\"Global Air Quality Dashboard\", style={\"textAlign\": \"center\", \"color\": \"#2C3E50\"})]),\n",
    "\n",
    "    # Control bar: pollutant dropdown + date picker\n",
    "    html.Div([\n",
    "        html.Div([\n",
    "            dcc.Dropdown(\n",
    "                id = \"pollutant dropdown\",\n",
    "                options = [{\"label\": p, \"value\": p} for p in pollutants],\n",
    "                value = \"PM2.5\",\n",
    "                clearable = False,\n",
    "                style={\"width\": \"220px\"}\n",
    "            )\n",
    "        ], style={\"display\": \"inline-block\", \"verticalAlign\": \"middle\", \"marginRight\": \"20px\"}),\n",
    "\n",
    "        html.Div([\n",
    "            dcc.DatePickerRange(\n",
    "                id='date-picker',\n",
    "                min_date_allowed=openaq_df['Date'].min(),\n",
    "                max_date_allowed=openaq_df['Date'].max(),\n",
    "                start_date=openaq_df['Date'].min(),\n",
    "                end_date=openaq_df['Date'].max(),\n",
    "                display_format='YYYY-MM-DD'\n",
    "            )\n",
    "        ], style={\"display\": \"inline-block\", \"verticalAlign\": \"middle\"}),\n",
    "\n",
    "    ], style={\"textAlign\": \"center\", \"padding\": \"10px\"}),\n",
    "\n",
    "    # Metric cards (Mean / Median / Max)\n",
    "    html.Div([\n",
    "        html.Div(id='avg-card', children=[html.H4(\"Mean\"), html.P(\"-\")], style={\"backgroundColor\": \"#F8F9FA\", \"padding\": \"12px\", \"borderRadius\": \"8px\", \"textAlign\": \"center\", \"width\": \"210px\"}),\n",
    "        html.Div(id='median-card', children=[html.H4(\"Median\"), html.P(\"-\")], style={\"backgroundColor\": \"#F8F9FA\", \"padding\": \"12px\", \"borderRadius\": \"8px\", \"textAlign\": \"center\", \"width\": \"210px\"}),\n",
    "        html.Div(id='max-card', children=[html.H4(\"Max\"), html.P(\"-\")], style={\"backgroundColor\": \"#F8F9FA\", \"padding\": \"12px\", \"borderRadius\": \"8px\", \"textAlign\": \"center\", \"width\": \"210px\"}),\n",
    "    ], style={\"display\": \"flex\", \"justifyContent\": \"center\", \"gap\": \"20px\", \"padding\": \"8px\"}),\n",
    "\n",
    "    # Main content: two charts per row using CSS grid\n",
    "    html.Div([\n",
    "        html.Div(dcc.Graph(id = \"map graph\", style={\"height\": \"420px\"}), style={\"width\": \"100%\", \"boxSizing\": \"border-box\", \"padding\": \"10px\"}),\n",
    "        html.Div(dcc.Graph(id = \"sunburst-chart\", style={\"height\": \"420px\"}), style={\"width\": \"100%\", \"boxSizing\": \"border-box\", \"padding\": \"10px\"}),\n",
    "        html.Div(dcc.Graph(id = \"time series graph\", style={\"height\": \"420px\"}), style={\"width\": \"100%\", \"boxSizing\": \"border-box\", \"padding\": \"10px\"}),\n",
    "        html.Div(dcc.Graph(id = \"bar chart\", style={\"height\": \"420px\"}), style={\"width\": \"100%\", \"boxSizing\": \"border-box\", \"padding\": \"10px\"}),\n",
    "    ], style={\"display\": \"grid\", \"gridTemplateColumns\": \"repeat(2, 1fr)\", \"gap\": \"12px\"}),\n",
    "], style={\"fontFamily\": \"Arial, sans-serif\"})\n",
    "\n",
    "\n",
    "# Callbacks\n",
    "@app.callback(\n",
    "    [Output(\"map graph\", \"figure\"),\n",
    "     Output(\"sunburst-chart\", \"figure\"),\n",
    "     Output(\"time series graph\", \"figure\"),\n",
    "     Output(\"bar chart\", \"figure\"),\n",
    "     Output(\"avg-card\", \"children\"),\n",
    "     Output(\"median-card\", \"children\"),\n",
    "     Output(\"max-card\", \"children\")],\n",
    "    [Input(\"pollutant dropdown\", \"value\"),\n",
    "     Input('date-picker', 'start_date'),\n",
    "     Input('date-picker', 'end_date'),\n",
    "     Input('map graph', 'clickData')]\n",
    ")\n",
    "\n",
    "def updated_graphs(selected_pollutant, start_date, end_date, map_click):\n",
    "    # Filter by pollutant (support 'All')\n",
    "    if selected_pollutant == 'All':\n",
    "        filtered = openaq_df.copy()\n",
    "    else:\n",
    "        filtered = openaq_df[openaq_df[\"Pollutant\"] == selected_pollutant].copy()\n",
    "\n",
    "    # Normalize incoming dates\n",
    "    if start_date is not None:\n",
    "        start = pd.to_datetime(start_date).date()\n",
    "    else:\n",
    "        start = openaq_df['Date'].min()\n",
    "    if end_date is not None:\n",
    "        end = pd.to_datetime(end_date).date()\n",
    "    else:\n",
    "        end = openaq_df['Date'].max()\n",
    "\n",
    "    filtered = filtered[(filtered['Date'] >= start) & (filtered['Date'] <= end)].copy()\n",
    "\n",
    "    # Map continent to filtered early so clicks can filter by continent reliably\n",
    "    if 'Country Label' in filtered.columns:\n",
    "        filtered['Continent'] = filtered['Country Label'].apply(resolve_continent)\n",
    "        filtered['Continent'] = filtered['Continent'].fillna('Unknown')\n",
    "    else:\n",
    "        filtered['Continent'] = 'Unknown'\n",
    "\n",
    "    # Keep a separate dataframe for the map so we don't drop rows needed for other charts (e.g., sunburst)\n",
    "    map_df = filtered.copy()\n",
    "\n",
    "    # Also add continent to the map dataframe so customdata can include it\n",
    "    if 'Country Label' in map_df.columns:\n",
    "        map_df['Continent'] = map_df['Country Label'].apply(resolve_continent)\n",
    "        map_df['Continent'] = map_df['Continent'].fillna('Unknown')\n",
    "    else:\n",
    "        map_df['Continent'] = 'Unknown'\n",
    "\n",
    "    # If user clicked on the map, try to resolve the continent and filter to it\n",
    "    try:\n",
    "        selected_continent = None\n",
    "        if map_click and isinstance(map_click, dict) and map_click.get('points'):\n",
    "            point = map_click['points'][0]\n",
    "            custom = point.get('customdata') or point.get('customData')\n",
    "            if custom:\n",
    "                # customdata commonly holds [Country Label, Continent]\n",
    "                if isinstance(custom, (list, tuple)) and len(custom) >= 2 and custom[1]:\n",
    "                    selected_continent = custom[1]\n",
    "                elif isinstance(custom, (list, tuple)) and len(custom) >= 1:\n",
    "                    selected_continent = resolve_continent(custom[0])\n",
    "                elif isinstance(custom, str):\n",
    "                    selected_continent = resolve_continent(custom)\n",
    "            else:\n",
    "                # Fallback: try hovertext/name and resolve\n",
    "                country_hint = point.get('hovertext') or point.get('hover_name') or point.get('location') or None\n",
    "                if country_hint:\n",
    "                    selected_continent = resolve_continent(country_hint)\n",
    "\n",
    "        if selected_continent:\n",
    "            # Filter both the main filtered and the map df to the selected continent\n",
    "            filtered = filtered[filtered['Continent'].fillna('Unknown') == selected_continent].copy()\n",
    "            map_df = map_df[map_df['Continent'].fillna('Unknown') == selected_continent].copy()\n",
    "    except Exception:\n",
    "        # If anything goes wrong parsing clickData, ignore and continue (no continent filter)\n",
    "        pass\n",
    "\n",
    "    # Clean up coordinates for map only\n",
    "    if 'Latitude' not in map_df.columns or 'Longitude' not in map_df.columns:\n",
    "        if 'Coordinates' in map_df.columns:\n",
    "            coords = map_df['Coordinates'].str.split(',', expand=True)\n",
    "            if coords.shape[1] >= 2:\n",
    "                map_df['Latitude'] = pd.to_numeric(coords.iloc[:, 0], errors='coerce')\n",
    "                map_df['Longitude'] = pd.to_numeric(coords.iloc[:, 1], errors='coerce')\n",
    "\n",
    "    # Drop rows missing coords in the map dataframe only\n",
    "    if 'Latitude' in map_df.columns and 'Longitude' in map_df.columns:\n",
    "        map_df = map_df.dropna(subset=['Latitude','Longitude'], how='any')\n",
    "\n",
    "    # remove known sentinel/outlier values and ensure numeric values for both filtered (used by charts) and map_df (used by map)\n",
    "    if 'Value' in filtered.columns:\n",
    "        filtered['Value'] = pd.to_numeric(filtered['Value'], errors='coerce')\n",
    "        filtered = filtered[~filtered['Value'].isin([-9999, 9999])]\n",
    "        filtered = filtered[filtered['Value'].notnull()]\n",
    "        filtered = filtered[filtered['Value'] >= 0]\n",
    "        filtered = filtered[filtered['Value'].replace([float('inf'), float('-inf')], pd.NA).notna()]\n",
    "\n",
    "        map_df['Value'] = pd.to_numeric(map_df['Value'], errors='coerce')\n",
    "        map_df = map_df[~map_df['Value'].isin([-9999, 9999])]\n",
    "        map_df = map_df[map_df['Value'].notnull()]\n",
    "        map_df = map_df[map_df['Value'] >= 0]\n",
    "        map_df = map_df[map_df['Value'].replace([float('inf'), float('-inf')], pd.NA).notna()]\n",
    "\n",
    "    # Compute metric cards\n",
    "    if filtered.empty or 'Value' not in filtered.columns:\n",
    "        avg_card = html.Div([html.H4(\"Mean\"), html.P(\"No data\")], style={\"padding\":\"6px\", \"textAlign\":\"center\"})\n",
    "        median_card = html.Div([html.H4(\"Median\"), html.P(\"No data\")], style={\"padding\":\"6px\", \"textAlign\":\"center\"})\n",
    "        max_card = html.Div([html.H4(\"Max\"), html.P(\"No data\")], style={\"padding\":\"6px\", \"textAlign\":\"center\"})\n",
    "    else:\n",
    "        avg_card = html.Div([html.H4(\"Mean\"), html.P(f\"{filtered['Value'].mean():.2f} μg/m³\")], style={\"padding\":\"6px\", \"textAlign\":\"center\"})\n",
    "        median_card = html.Div([html.H4(\"Median\"), html.P(f\"{filtered['Value'].median():.2f} μg/m³\")], style={\"padding\":\"6px\", \"textAlign\":\"center\"})\n",
    "        max_card = html.Div([html.H4(\"Max\"), html.P(f\"{filtered['Value'].max():.2f} μg/m³\")], style={\"padding\":\"6px\", \"textAlign\":\"center\"})\n",
    "\n",
    "    # Create a normalized marker size column to avoid invalid sizes (map only)\n",
    "    use_size = False\n",
    "    if 'Value' in map_df.columns and not map_df.empty:\n",
    "        q99 = map_df['Value'].quantile(0.99)\n",
    "        map_df['ValueCapped'] = map_df['Value'].clip(upper=q99)\n",
    "        vmin = map_df['ValueCapped'].min()\n",
    "        vmax = map_df['ValueCapped'].max()\n",
    "        if pd.isna(vmin) or pd.isna(vmax) or vmax == vmin:\n",
    "            map_df['MarkerSize'] = 8.0\n",
    "            use_size = True\n",
    "        else:\n",
    "            map_df['MarkerSize'] = 6.0 + ((map_df['ValueCapped'] - vmin) / (vmax - vmin)) * 14.0\n",
    "            # ensure numeric, finite, and positive\n",
    "            map_df['MarkerSize'] = pd.to_numeric(map_df['MarkerSize'], errors='coerce')\n",
    "            map_df = map_df[map_df['MarkerSize'].notnull() & (map_df['MarkerSize'] > 0) & map_df['MarkerSize'].apply(lambda x: pd.notna(x) and pd.api.types.is_number(x))]\n",
    "            use_size = not map_df['MarkerSize'].isnull().all()\n",
    "\n",
    "    # Map\n",
    "    try:\n",
    "        if map_df.empty or 'Latitude' not in map_df.columns or 'Longitude' not in map_df.columns:\n",
    "            map_fig = px.scatter_geo(lat=[], lon=[])\n",
    "            map_fig.update_layout(title='No data for selected pollutant/date range', margin=dict(l=0,r=0,t=40,b=0))\n",
    "        else:\n",
    "            map_args = dict(\n",
    "                data_frame=map_df,\n",
    "                lat=\"Latitude\",\n",
    "                lon=\"Longitude\",\n",
    "                color=\"Value\",\n",
    "                hover_name=\"City\",\n",
    "                hover_data=[\"Country Label\", \"Value\"],\n",
    "                title=f\"{selected_pollutant if selected_pollutant != 'All' else 'Pollutants'} Concentration Around the World\",\n",
    "                color_continuous_scale=\"Reds\",\n",
    "                custom_data=[\"Country Label\", \"Continent\"]\n",
    "            )\n",
    "            if use_size:\n",
    "                map_args['size'] = 'MarkerSize'\n",
    "                map_args['size_max'] = 20\n",
    "            # If size causes issues, omit it and fall back to color-only\n",
    "            try:\n",
    "                map_fig = px.scatter_geo(**map_args)\n",
    "                map_fig.update_layout(geo=dict(showframe=False, showcountries=True), margin=dict(l=0,r=0,t=40,b=0))\n",
    "            except Exception:\n",
    "                # fallback without size\n",
    "                map_args.pop('size', None)\n",
    "                map_fig = px.scatter_geo(**map_args)\n",
    "                map_fig.update_layout(geo=dict(showframe=False, showcountries=True), margin=dict(l=0,r=0,t=40,b=0))\n",
    "    except Exception as e:\n",
    "        map_fig = go.Figure()\n",
    "        map_fig.update_layout(title=f'Error creating map: {e}', margin=dict(l=0,r=0,t=40,b=0))\n",
    "\n",
    "    # Sunburst: show continents, countries and pollutant breakdowns (aggregated across selected date range)\n",
    "    try:\n",
    "        sb_df = filtered.copy()\n",
    "        if not sb_df.empty and 'Value' in sb_df.columns:\n",
    "            sb_df['Value'] = pd.to_numeric(sb_df['Value'], errors='coerce')\n",
    "            sb_df = sb_df[sb_df['Value'].notnull() & (sb_df['Value'] >= 0)]\n",
    "\n",
    "            # Map countries to continents using the robust resolver (ensure column exists in sb_df)\n",
    "            if 'Country Label' in sb_df.columns:\n",
    "                sb_df['Continent'] = sb_df['Country Label'].apply(resolve_continent)\n",
    "                sb_df['Continent'] = sb_df['Continent'].fillna('Unknown')\n",
    "            else:\n",
    "                sb_df['Continent'] = 'Unknown'\n",
    "\n",
    "            if selected_pollutant == 'All':\n",
    "                sunburst_df = sb_df.groupby(['Continent', 'Country Label', 'Pollutant'], as_index=False).agg(avg_value=('Value', 'mean'))\n",
    "                if sunburst_df.empty:\n",
    "                    sunburst_fig = go.Figure()\n",
    "                    sunburst_fig.update_layout(title='No data for sunburst', margin=dict(l=0,r=0,t=40,b=0))\n",
    "                else:\n",
    "                    sunburst_fig = px.sunburst(sunburst_df, path=['Continent', 'Country Label', 'Pollutant'], values='avg_value', color='avg_value', color_continuous_scale='bluered')\n",
    "                    sunburst_fig.update_layout(margin=dict(l=0,r=0,t=40,b=0), title='Average pollutant value by Continent > Country > Pollutant')\n",
    "            else:\n",
    "                # single pollutant: show continent -> country segments sized by avg pollutant value\n",
    "                sunburst_df = sb_df.groupby(['Continent', 'Country Label'], as_index=False).agg(avg_value=('Value', 'mean'))\n",
    "                if sunburst_df.empty:\n",
    "                    sunburst_fig = go.Figure()\n",
    "                    sunburst_fig.update_layout(title='No data for sunburst', margin=dict(l=0,r=0,t=40,b=0))\n",
    "                else:\n",
    "                    sunburst_fig = px.sunburst(sunburst_df, path=['Continent', 'Country Label'], values='avg_value', color='avg_value', color_continuous_scale='bluered')\n",
    "                    sunburst_fig.update_layout(margin=dict(l=0,r=0,t=40,b=0), title=f\"Average {selected_pollutant} by Continent and Country\")\n",
    "        else:\n",
    "            sunburst_fig = go.Figure()\n",
    "            sunburst_fig.update_layout(title='No data for sunburst', margin=dict(l=0,r=0,t=40,b=0))\n",
    "    except Exception as e:\n",
    "        sunburst_fig = go.Figure()\n",
    "        sunburst_fig.update_layout(title=f'Error creating sunburst: {e}', margin=dict(l=0,r=0,t=40,b=0))\n",
    "\n",
    "    # Bar chart: top 10 countries by average value for current filtered set\n",
    "    try:\n",
    "        if filtered.empty or 'Country Label' not in filtered.columns:\n",
    "            bar_fig = go.Figure()\n",
    "            bar_fig.update_layout(title='No data for bar chart', margin=dict(l=0,r=0,t=40,b=0))\n",
    "        else:\n",
    "            bar_df = filtered.groupby('Country Label', as_index=False).agg(avg_value=('Value', 'mean'))\n",
    "            bar_df = bar_df.sort_values('avg_value', ascending=False).head(10)\n",
    "            if bar_df.empty:\n",
    "                bar_fig = go.Figure()\n",
    "                bar_fig.update_layout(title='No data for bar chart', margin=dict(l=0,r=0,t=40,b=0))\n",
    "            else:\n",
    "                bar_fig = px.bar(bar_df, x='avg_value', y='Country Label', orientation='h', title='Top 10 countries by average value', labels={'avg_value':'Avg Value', 'Country Label': 'Country'})\n",
    "                bar_fig.update_layout(margin=dict(l=20,r=20,t=40,b=20), yaxis=dict(categoryorder='total ascending'))\n",
    "    except Exception as e:\n",
    "        bar_fig = go.Figure()\n",
    "        bar_fig.update_layout(title=f'Error creating bar chart: {e}', margin=dict(l=0,r=0,t=40,b=0))\n",
    "\n",
    "    # Time series (aggregate by date)\n",
    "    try:\n",
    "        if filtered.empty or 'Date' not in filtered.columns:\n",
    "            time_fig = go.Figure()\n",
    "            time_fig.update_layout(title='No data for time series', margin=dict(l=0,r=0,t=40,b=0))\n",
    "        else:\n",
    "            if selected_pollutant == 'All':\n",
    "                # When 'All' is selected, show each pollutant as a separate line\n",
    "                time_df = filtered.groupby(['Date', 'Pollutant'], as_index=False).agg(avg_value=(\"Value\", \"mean\"))\n",
    "                if time_df.empty:\n",
    "                    time_fig = go.Figure()\n",
    "                    time_fig.update_layout(title='No data for time series', margin=dict(l=0,r=0,t=40,b=0))\n",
    "                else:\n",
    "                    time_fig = px.line(time_df, x='Date', y='avg_value', color='Pollutant', title='Average Pollutants Over Time')\n",
    "                    time_fig.update_layout(margin=dict(l=20,r=20,t=40,b=20))\n",
    "            else:\n",
    "                time_df = filtered.groupby('Date', as_index=False).agg(avg_value=(\"Value\", \"mean\"))\n",
    "                time_fig = px.line(time_df, x='Date', y='avg_value', title=f\"Average {selected_pollutant} Over Time\")\n",
    "                time_fig.update_layout(margin=dict(l=20,r=20,t=40,b=20))\n",
    "    except Exception as e:\n",
    "        time_fig = go.Figure()\n",
    "        time_fig.update_layout(title=f'Error creating time series: {e}', margin=dict(l=0,r=0,t=40,b=0))\n",
    "\n",
    "    return map_fig, sunburst_fig, time_fig, bar_fig, avg_card, median_card, max_card"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f00657",
   "metadata": {},
   "source": [
    "# Run the dashboard\n",
    "\n",
    "Run the cell below to start the Dash app on port 8051. Interrupt the kernel to stop it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "00214157",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://0.0.0.0:8007/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x745fa18bb9b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Start the Dash app\n",
    "# Execute this cell to run the dashboard on port 8007.\n",
    "# Note: running this will block the kernel until you interrupt it (Kernel -> Interrupt).\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(debug=True, port=8007, host=\"0.0.0.0\", use_reloader=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
